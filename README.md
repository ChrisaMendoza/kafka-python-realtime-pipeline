# ğŸš€ Pipeline de DonnÃ©es Temps RÃ©el avec Kafka et Python

> Projet rÃ©alisÃ© dans le cadre du TP "Containerisation et Orchestration" â€” M1 Data Engineering & Computer Science

---

## ğŸ“‹ Description

Ce projet simule un **pipeline de donnÃ©es en temps rÃ©el** basÃ© sur une architecture producteur/consommateur avec Apache Kafka. Un service Python gÃ©nÃ¨re des transactions financiÃ¨res fictives, les publie dans un topic Kafka, et un second service Python les consomme et les traite.

L'ensemble de l'application est conteneurisÃ©e avec Docker, orchestrable localement via Docker Compose, et dÃ©ployable en production sur un cluster Kubernetes avec un pipeline CI/CD automatisÃ©.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 â”‚       â”‚                           â”‚       â”‚                 â”‚
â”‚  Producer       â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚  Kafka  +  Zookeeper      â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚  Consumer       â”‚
â”‚  (Python)       â”‚       â”‚  (Message Broker)         â”‚       â”‚  (Python)       â”‚
â”‚                 â”‚       â”‚                           â”‚       â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                             â”‚                                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                          Docker Compose / Kubernetes
```

**Flux de donnÃ©es :**
1. Le **Producer** gÃ©nÃ¨re des donnÃ©es de transactions fictives et les envoie dans le topic Kafka `transactions`
2. **Kafka** (avec Zookeeper pour la coordination) reÃ§oit et stocke les messages
3. Le **Consumer** s'abonne au topic et traite les messages reÃ§us en temps rÃ©el

---

## ğŸ“ Structure du Projet

```
kafka-python-realtime-pipeline/
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci-cd.yml            # Pipeline GitHub Actions
â”‚
â”œâ”€â”€ producer/
â”‚   â”œâ”€â”€ app.py                   # Script Python producteur (gÃ©nÃ©ration de transactions)
â”‚   â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â”‚   â””â”€â”€ Dockerfile               # Image Docker du producteur
â”‚
â”œâ”€â”€ consumer/
â”‚   â”œâ”€â”€ app.py                   # Script Python consommateur
â”‚   â”œâ”€â”€ requirements.txt         # DÃ©pendances Python
â”‚   â””â”€â”€ Dockerfile               # Image Docker du consommateur
â”‚
â”œâ”€â”€ deploy/                      # Manifestes Kubernetes
â”‚   â”œâ”€â”€ kafka-deployment.yaml
â”‚   â”œâ”€â”€ zookeeper-deployment.yaml
â”‚   â”œâ”€â”€ producer-deployment.yaml
â”‚   â”œâ”€â”€ consumer-deployment.yaml
â”‚   â”œâ”€â”€ configmap.yaml
â”‚   â””â”€â”€ secret.yaml
â”‚
â”œâ”€â”€ docker-compose.yml           # Orchestration locale de tous les services
â”œâ”€â”€ .dockerignore                # Fichiers exclus du contexte de build
â”œâ”€â”€ .gitignore                   # Fichiers exclus du dÃ©pÃ´t Git
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Technologies UtilisÃ©es

| Technologie | RÃ´le |
|---|---|
| **Python 3.11** | Scripts producteur et consommateur |
| **Apache Kafka** | Message broker temps rÃ©el |
| **Zookeeper** | Coordination et gestion du cluster Kafka |
| **Docker** | Conteneurisation des services |
| **Docker Compose** | Orchestration locale multi-conteneurs |
| **Kubernetes** | Orchestration en production |
| **GitHub Actions** | Pipeline CI/CD |

---

## âš™ï¸ PrÃ©requis

- [Docker Desktop](https://www.docker.com/products/docker-desktop/) installÃ© et dÃ©marrÃ©
- [Git](https://git-scm.com/)
- *(Pour Kubernetes)* [kubectl](https://kubernetes.io/docs/tasks/tools/) + [Minikube](https://minikube.sigs.k8s.io/) ou [kind](https://kind.sigs.k8s.io/)

---

## ğŸ³ Lancement avec Docker Compose (environnement local)

### 1. Cloner le projet

```bash
git clone https://github.com/ChrisaMendoza/kafka-python-realtime-pipeline.git
cd kafka-python-realtime-pipeline
```

### 2. Lancer tous les services

```bash
docker-compose up --build
```

> Le flag `--build` force la reconstruction des images Docker du producer et du consumer.

### 3. VÃ©rifier le bon fonctionnement

Dans les logs de la console, vous devriez observer :

```
zookeeper  | ... Started
kafka      | ... [KafkaServer id=1] started
producer   | âœ… Transaction envoyÃ©e : {"id": "txn-001", "montant": 142.50, ...}
consumer   | âœ… Message reÃ§u : {"id": "txn-001", "montant": 142.50, ...}
```

### 4. ArrÃªter et nettoyer

```bash
# ArrÃªter les services (Ctrl+C puis)
docker-compose down

# Supprimer Ã©galement les volumes
docker-compose down -v
```

---

## ğŸ” Commandes Utiles

```bash
# Voir les logs en direct d'un service
docker-compose logs -f producer
docker-compose logs -f consumer
docker-compose logs -f kafka

# RedÃ©marrer un service spÃ©cifique
docker-compose restart producer

# Lister les conteneurs actifs
docker ps

# Entrer dans un conteneur
docker exec -it kafka-producer bash
```

---

## â˜¸ï¸ DÃ©ploiement sur Kubernetes

### PrÃ©requis

Assurez-vous que votre cluster est actif :

```bash
minikube start
# ou
kind create cluster
```

### Appliquer les manifestes

```bash
kubectl apply -f deploy/
```

### VÃ©rifier le dÃ©ploiement

```bash
# Lister les pods
kubectl get pods

# Lister les services
kubectl get svc

# Lister les dÃ©ploiements
kubectl get deployments

# Voir les logs d'un pod
kubectl logs -f <nom-du-pod>
```

### DÃ©monstration de l'auto-rÃ©paration (self-healing)

Kubernetes redÃ©marre automatiquement les pods dÃ©faillants. Pour le vÃ©rifier :

```bash
# Supprimer un pod manuellement
kubectl delete pod <nom-du-pod-producer>

# Observer le redÃ©marrage automatique
kubectl get pods -w
```

---

## ğŸ”§ Variables d'Environnement

Les services utilisent les variables suivantes, dÃ©finies dans `docker-compose.yml` et gÃ©rÃ©es via `ConfigMap` / `Secret` dans Kubernetes :

| Variable | Description | Valeur par dÃ©faut |
|---|---|---|
| `KAFKA_BOOTSTRAP_SERVERS` | Adresse du broker Kafka | `kafka:9092` |
| `KAFKA_TOPIC` | Nom du topic Kafka | `transactions` |

> âš ï¸ Aucun secret n'est stockÃ© en clair dans le dÃ©pÃ´t Git ni dans les images Docker.

---

## ğŸ”„ Pipeline CI/CD

Le pipeline GitHub Actions (`.github/workflows/ci-cd.yml`) s'exÃ©cute automatiquement selon les rÃ¨gles suivantes :

| DÃ©clencheur | Action |
|---|---|
| Push sur `develop` | Build des images Docker + tests |
| CrÃ©ation d'un tag Git sur `main` | Build + Push vers le registre + DÃ©ploiement sur Kubernetes |

**Ã‰tapes du pipeline :**
1. ğŸ”¨ **Build** â€” Construction des images Docker (`producer`, `consumer`)
2. ğŸ“¦ **Push** â€” Publication des images vers le registre Docker Hub / GHCR
3. ğŸš€ **Deploy** â€” Application des manifestes Kubernetes (`kubectl apply`)

---

## ğŸ“Š Services et Ports

| Service | Port exposÃ© | Description |
|---|---|---|
| Zookeeper | `2181` | Coordination du cluster Kafka |
| Kafka | `9092` | Message broker principal |
| Producer | â€” | Service interne, sans port exposÃ© |
| Consumer | â€” | Service interne, sans port exposÃ© |

---

## ğŸ‘¥ Ã‰quipe

| Membre | RÃ´le |
|---|---|
| **Chrisa** | Chef de projet, Architecture, Documentation |
| **Flavie** | DÃ©veloppement Python (Producer & Consumer) |
| **Ekta** | Conteneurisation Docker (Dockerfiles) |
| **LÃ©ora** | Orchestration Docker Compose |
| **Angelikia** | Kubernetes & Pipeline CI/CD |

---

## ğŸ¤– Utilisation de l'IA

ConformÃ©ment aux consignes du TP, des outils d'IA (Claude, ChatGPT) ont Ã©tÃ© utilisÃ©s ponctuellement pour :
- La gÃ©nÃ©ration de gabarits de code Dockerfile et de manifestes Kubernetes
- La rÃ©daction de ce README

Tout le code gÃ©nÃ©rÃ© a Ã©tÃ© relu, compris, testÃ© et adaptÃ© par chaque membre de l'Ã©quipe.

---

## ğŸ“ˆ Axes d'AmÃ©lioration

- **Monitoring** : IntÃ©gration de Prometheus + Grafana pour visualiser les mÃ©triques (nombre de messages/s, latence)
- **Logging centralisÃ©** : DÃ©ploiement d'une stack Loki + Promtail pour agrÃ©ger les logs de tous les services
- **SÃ©curitÃ©** : Scan des images Docker avec Trivy dans le pipeline CI/CD
- **Gestion des dÃ©pendances** : Migration vers [uv](https://github.com/astral-sh/uv) comme gestionnaire de dÃ©pendances Python

---

## ğŸ“ Informations Projet

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du cours **"Containerisation et Orchestration"** â€” M1 Data Engineering & Computer Science.
